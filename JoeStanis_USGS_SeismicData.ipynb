{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "6dtFCNppUscI"
      ],
      "authorship_tag": "ABX9TyNAVNg7CUNIKznzoAY8ToTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joestanis/USGS-SAC-25-12553801-DE-RM/blob/main/JoeStanis_USGS_SeismicData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervisory Computer Scientist, Vacancy Announcement USGS-SAC-25-12553801-DE-RM\n",
        "\n",
        "## Purpose\n",
        "\n",
        "A project designed and developed using specific objectives, emphasizing code efficiency, readability, and adherence to best practices.\n",
        "\n",
        "Python 3 is the language used for program code, with coding style following recommendations of *Python Enhancement Proposal 8* [ https://peps.python.org/pep-0008/ ]."
      ],
      "metadata": {
        "id": "jHdH8u2MS03o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the required libraries."
      ],
      "metadata": {
        "id": "l6wKZzyaUR0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install obspy\n",
        "import obspy\n",
        "import sqlite3"
      ],
      "metadata": {
        "id": "rZzwJgoUUdoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3584d9-bedc-45d7-bb62-b7276845f1f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from obspy) (3.8.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from obspy) (5.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from obspy) (75.1.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from obspy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->obspy) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the global variables."
      ],
      "metadata": {
        "id": "nrAe3ljAUj_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Array defining paths to each miniSEED file.\n",
        "mseed_files: list[str] = [\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP01.mseed',\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP02.mseed',\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP03.mseed'\n",
        "]\n",
        "\n",
        "# Name of the database where miniSEED data will be stored.\n",
        "mseed_db_filename: str = 'usgs_miniseed_data.sqlite.db'\n",
        "\n",
        "# Array which will hold the consolidated list of all miniSEED traces.\n",
        "mseed_traces = []\n",
        "\n",
        "# Hold the metadata about each file in a separate variable for use with the final visualization.\n",
        "mseed_sources_metadata: list[dict[str:any]] = []\n",
        "\n",
        "# For modularity define the database table names in a dictionary rather than hardcoding them directly into the scripts.\n",
        "table_names: dict[str, str] = {\n",
        "    'network_codes': 'network_codes',\n",
        "    'station_codes': 'station_codes',\n",
        "    'location_codes': 'location_codes',\n",
        "    'channel_codes': 'channel_codes',\n",
        "    'stations': 'stations',\n",
        "    'mseed_traces': 'mseed_traces',\n",
        "    'mseed_samples': 'mseed_samples'\n",
        "}\n"
      ],
      "metadata": {
        "id": "0CHoOhP9Vyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the utility functions."
      ],
      "metadata": {
        "id": "6dtFCNppUscI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function which executes a general SQL statement against a SQLite database.\n",
        "def sql_exec(db_name: str = None,\n",
        "             sql: str = ';') -> int:\n",
        "    \"\"\"Executes a general SQLite statement.\n",
        "\n",
        "    :param db_name: SQLite database file name\n",
        "    :param sql: SQL statement to execute\n",
        "    :return: Integer 1 if successful\n",
        "    \"\"\"\n",
        "\n",
        "    if db_name is None:\n",
        "        raise ValueError('Missing the database file name.')\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=db_name) as db_conn:\n",
        "            db_cursor = db_conn.cursor()\n",
        "            db_cursor.execute(sql)\n",
        "            db_conn.commit()\n",
        "            return 1\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n",
        "\n",
        "\n",
        "# Function which inserts a single data row into a SQLite table.\n",
        "def sql_insert(db_name: str = None,\n",
        "               table_name: str = None,\n",
        "               insert_data: dict[str, any] = None) -> int:\n",
        "    \"\"\"Inserts a single data row into a specified table and returns the ID of the last successfully inserted row\n",
        "\n",
        "    :param db_name: SQLite database file name\n",
        "    :param table_name: Table where the data will be inserted\n",
        "    :param insert_data: Dictionary of name-value pairs, where key is the field name and value is the data to insert\n",
        "    :return: ID of the inserted row, or 0 if unsuccessful\n",
        "    \"\"\"\n",
        "\n",
        "    if db_name is None:\n",
        "        raise ValueError('Missing the database file name.')\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if insert_data.__len__() < 1:\n",
        "        raise ValueError('Missing {field:value} dictionary to insert.')\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=db_name, isolation_level='DEFERRED') as db_conn:\n",
        "            db_cursor = db_conn.cursor()\n",
        "\n",
        "            # Extract the field names and values from the data insert dictionary. Extracting one name-value pair at a time to ensure associative integrity.\n",
        "            row_fields = []\n",
        "            row_values = []\n",
        "\n",
        "            for key, value in insert_data.items():\n",
        "                row_fields.append(f\"[{key}]\")\n",
        "                row_values.append(value)\n",
        "\n",
        "            # Build the insert statement from name-value pairs, telling SQLite to honor any UNIQUE constrains during the insert operation.\n",
        "            # sql_query = f\"INSERT OR IGNORE INTO [{table_name}] ({','.join(row_fields)}) VALUES ({','.join(row_values)});\"\n",
        "            param_placeholders = ','.join('?' * len(row_values))\n",
        "            sql_query = f\"INSERT OR IGNORE INTO [{table_name}] ({','.join(row_fields)}) VALUES ({param_placeholders});\"\n",
        "\n",
        "            db_cursor.execute(sql_query, row_values)\n",
        "            db_conn.commit()\n",
        "            if db_cursor.lastrowid:\n",
        "                return db_cursor.lastrowid\n",
        "            else:\n",
        "                # Failed insert can result in last row ID of None, so ensure the function returns an integer.\n",
        "                return 0\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n",
        "\n",
        "\n",
        "# Function which inserts multiple data rows into a SQLite table.\n",
        "def sql_insert_many(db_name: str = None,\n",
        "                    table_name: str = None,\n",
        "                    field_names: list[str] = None,\n",
        "                    field_values: list[tuple[any]] = None) -> int:\n",
        "    \"\"\"Bulk inserts data into a specified table and returns a count of inserted rows.\n",
        "\n",
        "    :param db_name: SQLite database file name\n",
        "    :param table_name: Table where the data will be inserted\n",
        "    :param field_names: List of field names to target for data insertion\n",
        "    :param field_values: Data to insert into tio table, passed as tuple list items, with data in the same order as the field names\n",
        "    :return: Count of the inserted rows\n",
        "    \"\"\"\n",
        "\n",
        "    if db_name is None:\n",
        "        raise ValueError('Missing the database file name.')\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if field_names is None:\n",
        "        raise ValueError('Missing names of fields for insert.')\n",
        "\n",
        "    if field_values is None:\n",
        "        raise ValueError('Missing values to insert for each field.')\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=db_name, isolation_level='DEFERRED') as db_conn:\n",
        "            db_cursor = db_conn.cursor()\n",
        "\n",
        "            # Build the insert statement from name-value pairs, telling SQLite to honor any UNIQUE constrains during the insert operation.\n",
        "            param_placeholders = ','.join('?' * len(field_values[0]))\n",
        "            sql_query = f\"INSERT OR IGNORE INTO [{table_name}] ({','.join(field_names)}) VALUES ({param_placeholders});\"\n",
        "\n",
        "            db_cursor.executemany(sql_query, field_values)\n",
        "            db_conn.commit()\n",
        "            if db_cursor.lastrowid:\n",
        "                return db_cursor.lastrowid\n",
        "            else:\n",
        "                # Failed insert can result in last row ID of None, so ensure the function returns an integer.\n",
        "                return 0\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n",
        "\n",
        "\n",
        "def sql_fetch_code_id(db_name: str = None,\n",
        "                      table_name: str = None,\n",
        "                      code_field: str = None,\n",
        "                      code_value: str = None,\n",
        "                      insert_if_missing: bool = True) -> int:\n",
        "    \"\"\"Returns the row ID for a provided code value. Optionally insert a new code value if none was found.\n",
        "\n",
        "    :param db_name: SQLite database file name\n",
        "    :param table_name: Table containing the code values\n",
        "    :param code_field: Field to search for the provided code value\n",
        "    :param code_value: Lookup this code value to fetch its ID\n",
        "    :param insert_if_missing: If True, and the provided code value is not found, then try to insert it as a new code value\n",
        "    :return: Integer ID number of the code value, otherwise 0 if not found\n",
        "    \"\"\"\n",
        "    if db_name is None:\n",
        "        raise ValueError('Missing the database file name.')\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if code_field is None:\n",
        "        raise ValueError('Missing the field name containing the codes.')\n",
        "\n",
        "    if code_value is None:\n",
        "        raise ValueError('Missing the code value to search.')\n",
        "\n",
        "    try:\n",
        "        sql_query = f\"SELECT [id] FROM [{table_name}] WHERE [{code_field}] = '{code_value}';\"\n",
        "\n",
        "        with sqlite3.connect(database=db_name) as db_conn:\n",
        "            db_conn.row_factory = sqlite3.Row\n",
        "            db_cursor = db_conn.cursor()\n",
        "            db_cursor.execute(sql_query)\n",
        "            db_conn.commit()\n",
        "            result_record = db_cursor.fetchone()\n",
        "\n",
        "            if result_record:\n",
        "                # Found a matching code\n",
        "                return result_record['id']\n",
        "\n",
        "            elif insert_if_missing:\n",
        "                # No matching code but attempt to insert and re-fetch\n",
        "                code_data = {\n",
        "                    code_field: code_value\n",
        "                }\n",
        "                sql_last_row_id = sql_insert(db_name=db_name, table_name=table_name, insert_data=code_data)\n",
        "                return sql_last_row_id\n",
        "\n",
        "            else:\n",
        "                # No matching code\n",
        "                return 0\n",
        "\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n",
        "\n",
        "\n",
        "def sql_truncate_table(db_name: str = None,\n",
        "                       table_name: str = None) -> int:\n",
        "    \"\"\"Empties all data from a specified table, essentially truncating the table.\n",
        "\n",
        "    :param db_name: SQLite database file name\n",
        "    :param table_name: Table to empty of data\n",
        "    :return: Returns whatever result was received from the call to sql_exec\n",
        "    \"\"\"\n",
        "    if db_name is None:\n",
        "        raise ValueError('Missing the database file name.')\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    try:\n",
        "        sql_query = f\"DELETE FROM [{table_name}];\"\n",
        "        sql_result = sql_exec(db_name=db_name, sql=sql_query)\n",
        "        return sql_result\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n"
      ],
      "metadata": {
        "id": "FqbHXqd7VxtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the mseed files."
      ],
      "metadata": {
        "id": "DO1kwaTxU4s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if mseed_files.__len__() < 1:\n",
        "        print('Error: No miniSEED files to process.')\n",
        "\n",
        "    else:\n",
        "        print(f\"Attempting to import data from {mseed_files.__len__()} miniSEED files.\")\n",
        "\n",
        "        for current_file in mseed_files:\n",
        "            print(f\"Processing '{current_file}'\")\n",
        "\n",
        "            try:\n",
        "                current_stream = obspy.read(pathname_or_url=current_file)\n",
        "                print(f\"Loaded {current_stream.__len__()} traces from the file.\")\n",
        "\n",
        "                mseed_sources_metadata.append({'mseed_file': current_file,\n",
        "                                               'mseed_metadata': current_stream.traces[0].meta.mseed})\n",
        "\n",
        "                for current_trace in current_stream:\n",
        "                    mseed_traces.append(current_trace)\n",
        "\n",
        "            except IOError:\n",
        "                print(f\"Exception: Unable to open file '{current_file}'.\")\n",
        "\n",
        "        print(f\"Imported a total of {mseed_traces.__len__()} traces from all sources.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "dh4jRIoMVxEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a database with proper normal form and constraints."
      ],
      "metadata": {
        "id": "63fpELbwIxNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    # Create the database schema for the NETWORK foreign key table.\n",
        "    print(f\"Creating the [{table_names['network_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['network_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                network_code TEXT NOT NULL,\n",
        "                CONSTRAINT network_code_unique UNIQUE (network_code));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the NETWORK table.\n",
        "        print(f\"Initializing the [{table_names['network_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['network_codes'])\n",
        "\n",
        "    # Create the database schema for the STATION foreign key table.\n",
        "    print(f\"Creating the [{table_names['station_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['station_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                station_code TEXT NOT NULL,\n",
        "                CONSTRAINT station_code_unique UNIQUE (station_code));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the STATION table.\n",
        "        print(f\"Initializing the [{table_names['station_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['station_codes'])\n",
        "\n",
        "    # Create the database schema for the LOCATION foreign key table.\n",
        "    print(f\"Creating the [{table_names['location_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['location_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                location_code TEXT NOT NULL,\n",
        "                CONSTRAINT location_code_unique UNIQUE (location_code));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the LOCATION table.\n",
        "        print(f\"Initializing the [{table_names['location_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['location_codes'])\n",
        "\n",
        "    # Create the database schema for the CHANNEL foreign key table.\n",
        "    print(f\"Creating the [{table_names['channel_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['channel_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                channel_code TEXT NOT NULL,\n",
        "                CONSTRAINT channel_code_unique UNIQUE (channel_code));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the CHANNEL table.\n",
        "        print(f\"Initializing the [{table_names['channel_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['channel_codes'])\n",
        "\n",
        "    # Create the database schema for the TRACES table.\n",
        "    print(f\"Creating the [{table_names['mseed_traces']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['mseed_traces']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                network_id INTEGER NOT NULL, -- Foreign key to NETWORK.id\n",
        "                station_id INTEGER NOT NULL, -- Foreign key to STATION.id\n",
        "                location_id INTEGER NOT NULL, -- Foreign key to LOCATION.id\n",
        "                channel_id INTEGER NOT NULL, -- Foreign key to CHANNEL.id\n",
        "                starttime REAL, -- Unix timestamp UTC\n",
        "                endtime REAL, -- Unix timestamp UTC\n",
        "                sampling_rate REAL,\n",
        "                delta REAL,\n",
        "                npts INTEGER,\n",
        "                calib REAL,\n",
        "                FOREIGN KEY (network_id) REFERENCES {table_names['network_codes']}(id),\n",
        "                FOREIGN KEY (station_id) REFERENCES {table_names['station_codes']}(id),\n",
        "                FOREIGN KEY (location_id) REFERENCES {table_names['location_codes']}(id),\n",
        "                FOREIGN KEY (channel_id) REFERENCES {table_names['channel_codes']}(id));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the TRACES table.\n",
        "        print(f\"Initializing the [{table_names['mseed_traces']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['mseed_traces'])\n",
        "\n",
        "    # Create the database schema for the SAMPLES table.\n",
        "    print(f\"Creating the [{table_names['mseed_samples']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['mseed_samples']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                trace_id INTEGER,\n",
        "                sample_num INTEGER,\n",
        "                sample_value INTEGER,\n",
        "                FOREIGN KEY (trace_id) REFERENCES {table_names['mseed_traces']}(id));\"\"\"\n",
        "    sql_result = sql_exec(db_name=mseed_db_filename, sql=sql_query)\n",
        "    if sql_result:\n",
        "        # Reset the SAMPLES table.\n",
        "        print(f\"Initializing the [{table_names['mseed_samples']}] table.\")\n",
        "        sql_result = sql_truncate_table(db_name=mseed_db_filename, table_name=table_names['mseed_samples'])\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "Lz7dBheJVsob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the data into the newly created database."
      ],
      "metadata": {
        "id": "fYDRa2gsJPWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if mseed_traces.__len__() < 1:\n",
        "        print('Error: no miniSEED traces to import.')\n",
        "    else:\n",
        "\n",
        "        counter_traces = 1\n",
        "        for current_trace in mseed_traces:\n",
        "            print(\n",
        "                f\"Importing trace {counter_traces} of {mseed_traces.__len__()} into the [{table_names['mseed_traces']}] table.\")\n",
        "            trace_data = {\n",
        "                'network_id': sql_fetch_code_id(db_name=mseed_db_filename, table_name=table_names['network_codes'],\n",
        "                                                code_field='network_code', code_value=current_trace.stats.network),\n",
        "                'station_id': sql_fetch_code_id(db_name=mseed_db_filename, table_name=table_names['station_codes'],\n",
        "                                                code_field='station_code', code_value=current_trace.stats.station),\n",
        "                'location_id': sql_fetch_code_id(db_name=mseed_db_filename, table_name=table_names['location_codes'],\n",
        "                                                 code_field='location_code', code_value=current_trace.stats.location),\n",
        "                'channel_id': sql_fetch_code_id(db_name=mseed_db_filename, table_name=table_names['channel_codes'],\n",
        "                                                code_field='channel_code', code_value=current_trace.stats.channel),\n",
        "                'starttime': current_trace.stats.starttime.timestamp,\n",
        "                'endtime': current_trace.stats.endtime.timestamp,\n",
        "                'sampling_rate': current_trace.stats.sampling_rate,\n",
        "                'delta': current_trace.stats.delta,\n",
        "                'npts': current_trace.stats.npts,\n",
        "                'calib': current_trace.stats.calib\n",
        "            }\n",
        "\n",
        "            trace_id_last_insert = sql_insert(db_name=mseed_db_filename, table_name=table_names['mseed_traces'],\n",
        "                                              insert_data=trace_data)\n",
        "            counter_traces += 1\n",
        "\n",
        "            if trace_id_last_insert:\n",
        "                # Positive row ID, implying a successful insert, so proceed with loading the associated trace samples.\n",
        "                print(\n",
        "                    f\"Importing {current_trace.data.__len__()} samples into the [{table_names['mseed_samples']}] table.\")\n",
        "\n",
        "                samples_field_names = [\n",
        "                    'trace_id',\n",
        "                    'sample_num',\n",
        "                    'sample_value'\n",
        "                ]\n",
        "\n",
        "                # Build the samples data for bulk import.\n",
        "                samples_data = []\n",
        "                samples_list = current_trace.data.tolist()\n",
        "                counter_samples = 0\n",
        "                for current_sample in samples_list:\n",
        "                    samples_data.append((trace_id_last_insert, counter_samples, current_sample))\n",
        "                    counter_samples += 1\n",
        "\n",
        "                # For improved performance use sql_insert_many to bulk import the sample data points rather than importing one at a time using sql_insert\n",
        "                sql_insert_many(db_name=mseed_db_filename, table_name=table_names['mseed_samples'],\n",
        "                                field_names=samples_field_names, field_values=samples_data)\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "2nfAL5tBVwLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a visualization for the data."
      ],
      "metadata": {
        "id": "f6IG4LfwZ0-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('TODO')"
      ],
      "metadata": {
        "id": "vOiB7Rk1Z4Ln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
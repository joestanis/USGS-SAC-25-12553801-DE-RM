{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzfQ54850rZpBIZelB9G2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joestanis/USGS-SAC-25-12553801-DE-RM/blob/main/JoeStanis_USGS_SeismicData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervisory Computer Scientist, Vacancy Announcement USGS-SAC-25-12553801-DE-RM\n",
        "\n",
        "## Purpose\n",
        "\n",
        "A project designed and developed using specific objectives, emphasizing code efficiency, readability, and adherence to best practices.\n",
        "\n",
        "Python 3 is the language used for program code, with coding style following recommendations of *Python Enhancement Proposal 8* [ https://peps.python.org/pep-0008/ ]."
      ],
      "metadata": {
        "id": "jHdH8u2MS03o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the required libraries."
      ],
      "metadata": {
        "id": "l6wKZzyaUR0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the external ObSpy library. After installation if other dependencies were updated Google Colab might require a restart of the session.\n",
        "!pip install obspy\n",
        "\n",
        "# Import critical modules\n",
        "import obspy\n",
        "import sqlite3\n",
        "import requests\n",
        "import xml.etree.ElementTree\n",
        "import re"
      ],
      "metadata": {
        "id": "rZzwJgoUUdoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d69734-e1d1-4759-8ab0-8dd68c0ec27d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obspy in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from obspy) (3.8.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from obspy) (5.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from obspy) (75.1.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/dist-packages (from obspy) (1.4.54)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from obspy) (4.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from obspy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->obspy) (2.8.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2->obspy) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->obspy) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the global variables."
      ],
      "metadata": {
        "id": "nrAe3ljAUj_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Array defining paths to each miniSEED file.\n",
        "mseed_files: list[str] = [\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP01.mseed',\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP02.mseed',\n",
        "    'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP03.mseed'\n",
        "]\n",
        "\n",
        "# Name of the database where miniSEED data will be stored.\n",
        "mseed_db_filename: str = 'usgs_miniseed_data.sqlite.db'\n",
        "\n",
        "# Array which will hold the consolidated list of all miniSEED traces.\n",
        "mseed_traces = []\n",
        "\n",
        "# Hold the metadata about each file in a separate variable for use with the final visualization.\n",
        "mseed_sources_metadata: list[dict[str:any]] = []\n",
        "\n",
        "# For modularity define the database table names in a dictionary rather than hardcoding them directly into the scripts.\n",
        "table_names: dict[str, str] = {\n",
        "    'network_codes': 'network_codes',\n",
        "    'station_codes': 'station_codes',\n",
        "    'location_codes': 'location_codes',\n",
        "    'channel_codes': 'channel_codes',\n",
        "    'stations': 'stations',\n",
        "    'mseed_traces': 'mseed_traces',\n",
        "    'mseed_samples': 'mseed_samples',\n",
        "    'site_info': 'site_info'\n",
        "}\n",
        "\n",
        "# Define the base URL to query IRIS API.\n",
        "iris_api_url_base = 'https://service.iris.edu/fdsnws/station/1/query'\n"
      ],
      "metadata": {
        "id": "0CHoOhP9Vyf_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the utility functions."
      ],
      "metadata": {
        "id": "6dtFCNppUscI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to execute a general SQL statement against the database."
      ],
      "metadata": {
        "id": "eCFELololOnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_exec(sql: str = ';') -> list:\n",
        "    \"\"\"Executes a general SQLite statement.\n",
        "\n",
        "    :param sql: SQL statement to execute\n",
        "    :return: List containing the selected data, if any\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=mseed_db_filename) as db_conn:\n",
        "            db_conn.row_factory = sqlite3.Row\n",
        "            db_cursor = db_conn.cursor()\n",
        "            db_cursor.execute(sql)\n",
        "            db_conn.commit()\n",
        "            return db_cursor.fetchall()\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n"
      ],
      "metadata": {
        "id": "FqbHXqd7VxtB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to insert a single data row into a database table."
      ],
      "metadata": {
        "id": "EGyaxmhlhgi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_insert(table_name: str = None,\n",
        "               insert_data: dict[str, any] = None) -> int:\n",
        "    \"\"\"Inserts a single data row into a specified table and returns the ID of the last successfully inserted row.\n",
        "\n",
        "    :param table_name: Table where the data will be inserted\n",
        "    :param insert_data: Dictionary of name-value pairs, where key is the field name and value is the data to insert\n",
        "    :return: ID of the inserted row, or 0 if unsuccessful\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if insert_data.__len__() < 1:\n",
        "        raise ValueError('Missing {field:value} dictionary to insert.')\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=mseed_db_filename, isolation_level='DEFERRED') as db_conn:\n",
        "            db_cursor = db_conn.cursor()\n",
        "\n",
        "            # Extract the field names and values from the data insert dictionary. Extracting one name-value pair at a time to ensure associative integrity.\n",
        "            row_fields = []\n",
        "            row_values = []\n",
        "\n",
        "            for key, val in insert_data.items():\n",
        "                row_fields.append(f\"[{key}]\")\n",
        "                row_values.append(val)\n",
        "\n",
        "            # Build the insert statement from name-value pairs, telling SQLite to honor any UNIQUE constrains during the insert operation.\n",
        "            param_placeholders = ','.join('?' * len(row_values))\n",
        "            sql_query = f\"INSERT OR IGNORE INTO [{table_name}] ({','.join(row_fields)}) VALUES ({param_placeholders});\"\n",
        "\n",
        "            db_cursor.execute(sql_query, row_values)\n",
        "            db_conn.commit()\n",
        "            if db_cursor.lastrowid:\n",
        "                return db_cursor.lastrowid\n",
        "            else:\n",
        "                # Failed insert can result in last row ID of None, so ensure the function returns an integer.\n",
        "                return 0\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n"
      ],
      "metadata": {
        "id": "4dI4FG-thgu5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to fast insert multiple data rows into a database table."
      ],
      "metadata": {
        "id": "ok_moWDxh0G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_insert_many(table_name: str = None,\n",
        "                    field_names: list[str] = None,\n",
        "                    field_values: list[tuple[any]] = None) -> int:\n",
        "    \"\"\"Bulk inserts data into a specified table and returns a count of inserted rows.\n",
        "\n",
        "    :param table_name: Table where the data will be inserted\n",
        "    :param field_names: List of field names to target for data insertion\n",
        "    :param field_values: Data to insert into tio table, passed as tuple list items, with data in the same order as the field names\n",
        "    :return: Count of the inserted rows\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if field_names is None:\n",
        "        raise ValueError('Missing names of fields for insert.')\n",
        "\n",
        "    if field_values is None:\n",
        "        raise ValueError('Missing values to insert for each field.')\n",
        "\n",
        "    try:\n",
        "        with sqlite3.connect(database=mseed_db_filename, isolation_level='DEFERRED') as db_conn:\n",
        "            db_cursor = db_conn.cursor()\n",
        "\n",
        "            # Build the insert statement from name-value pairs, telling SQLite to honor any UNIQUE constrains during the insert operation.\n",
        "            param_placeholders = ','.join('?' * len(field_values[0]))\n",
        "            sql_query = f\"INSERT OR IGNORE INTO [{table_name}] ({','.join(field_names)}) VALUES ({param_placeholders});\"\n",
        "\n",
        "            db_cursor.executemany(sql_query, field_values)\n",
        "            db_conn.commit()\n",
        "            if db_cursor.lastrowid:\n",
        "                return db_cursor.lastrowid\n",
        "            else:\n",
        "                # Failed insert can result in last row ID of None, so ensure the function returns an integer.\n",
        "                return 0\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n"
      ],
      "metadata": {
        "id": "QBZsqvqAh0Sq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to fetch rows from a database table."
      ],
      "metadata": {
        "id": "oMlL7cT1h7Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_fetch_rows(table_name: str = None,\n",
        "                   search_values: dict[str:any] = None,\n",
        "                   return_fields: list[str] = None,\n",
        "                   limit_rows: int = 0,\n",
        "                   insert_if_missing: bool = False) -> dict[str, any]:\n",
        "    \"\"\"Returns the row data for a provided search values. Optionally attempts to insert row with the search values if none was found.\n",
        "\n",
        "    :param table_name: Table containing the data to search\n",
        "    :param search_values: Criteria to use for searching the rows\n",
        "    :param return_fields: List containing the fields of data to return from the row. If omitted, None, or an empty list then all fields for that row are returned.\n",
        "    :param limit_rows: List containing the fields of data to return from the row. If omitted, None, or an empty list then all fields for that row are returned.\n",
        "    :param insert_if_missing: If True, and the provided value is not found, then try to insert a new row with this value\n",
        "    :return: Dictionary containing the specified row data for the requested search values\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    if search_values is None:\n",
        "        raise ValueError('Missing the search criteria.')\n",
        "\n",
        "    try:\n",
        "        select_fields = '*'\n",
        "        if return_fields is not None:\n",
        "            select_fields = '[' + '],['.join(return_fields) + ']'\n",
        "\n",
        "        where_fields = ['1=1']\n",
        "        for key, val in search_values.items():\n",
        "            where_fields.append(f\"[{key}]='{val}'\")\n",
        "\n",
        "        sql_query = f\"SELECT {select_fields} FROM [{table_name}] WHERE {' AND '.join(where_fields)}\"\n",
        "        if limit_rows > 0:\n",
        "            sql_query += f\" LIMIT {limit_rows}\"\n",
        "        sql_query += ';'\n",
        "\n",
        "        with sqlite3.connect(database=mseed_db_filename) as db_conn:\n",
        "            db_conn.row_factory = sqlite3.Row\n",
        "            db_cursor = db_conn.cursor()\n",
        "            db_cursor.execute(sql_query)\n",
        "            db_conn.commit()\n",
        "            result_record = db_cursor.fetchall()\n",
        "\n",
        "            if result_record:\n",
        "                # Found a matching row.\n",
        "                return result_record\n",
        "\n",
        "            if insert_if_missing:\n",
        "                # No matching record but attempt to insert a new record and re-fetch.\n",
        "                sql_last_row_id = sql_insert(table_name=table_name, insert_data=search_values)\n",
        "                if sql_last_row_id is None:\n",
        "                    # Failed to insert the new code data\n",
        "                    return {}\n",
        "\n",
        "                # Try again to fetch the station location info.\n",
        "                return sql_fetch_rows(table_name=table_name, search_values=search_values,\n",
        "                                      return_fields=return_fields, limit_rows=limit_rows)\n",
        "\n",
        "            # No matching code.\n",
        "            return {}\n",
        "\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n",
        "\n",
        "    finally:\n",
        "        db_conn.close()\n"
      ],
      "metadata": {
        "id": "Q8mAwgcph7hE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to empty a database table."
      ],
      "metadata": {
        "id": "7o1GPFrTiDUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sql_truncate_table(table_name: str = None) -> list:\n",
        "    \"\"\"Empties all data from a specified table, essentially truncating the table.\n",
        "\n",
        "    :param table_name: Table to empty of data\n",
        "    :return: Returns whatever result was received from the call to sql_exec\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name for data insert.')\n",
        "\n",
        "    try:\n",
        "        sql_query = f\"DELETE FROM [{table_name}];\"\n",
        "        return sql_exec(sql=sql_query)\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n"
      ],
      "metadata": {
        "id": "48blvhOwiDez"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to search for a given column value and return the corresponding row ID."
      ],
      "metadata": {
        "id": "1cB0KGk7NGxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fields_to_id(table_name: str = None,\n",
        "                 search_values: dict[str, any] = None,\n",
        "                 insert_if_missing: bool = False) -> int:\n",
        "    \"\"\"Search a table for a specific column value. If found, return the first row ID in the set.\n",
        "\n",
        "    :param table_name: Table to search\n",
        "    :param search_values: Dictionary with keys as field names and values as search criteria\n",
        "    :param insert_if_missing: If True, and the provided value is not found, then try to insert the search data into a new row\n",
        "    :return: ID of the matching row\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name to search.')\n",
        "\n",
        "    if search_values is None:\n",
        "        raise ValueError('Missing the search data to locate the row ID.')\n",
        "\n",
        "    try:\n",
        "        sql_result = sql_fetch_rows(table_name=table_name, search_values=search_values, return_fields=['id'],\n",
        "                                    limit_rows=1, insert_if_missing=insert_if_missing)\n",
        "        return sql_result[0]['id']\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n"
      ],
      "metadata": {
        "id": "9ULHsIV2NIj8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to locate a row ID and return the requested column's value."
      ],
      "metadata": {
        "id": "kevKdFn1NQvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def id_to_fields(table_name: str = None,\n",
        "                 search_id: int = 0,\n",
        "                 return_fields: list = None) -> dict[str, any]:\n",
        "    \"\"\"Search a table for a given row ID. If found, return the requested column data.\n",
        "\n",
        "    :param table_name: Table to search\n",
        "    :param search_id: ID of the row to locate\n",
        "    :param return_fields: List containing fields to retrieve if found a matching row\n",
        "    :return: A dictionary of field values from the matching row\n",
        "    \"\"\"\n",
        "\n",
        "    if table_name is None:\n",
        "        raise ValueError('Missing the table name to search.')\n",
        "\n",
        "    if return_fields is None:\n",
        "        raise ValueError('Missing which field column to retrieve and return the data.')\n",
        "\n",
        "    try:\n",
        "        sql_result = sql_fetch_rows(table_name=table_name, search_values={'id': search_id}, return_fields=return_fields,\n",
        "                                    limit_rows=1)\n",
        "        return sql_result[0]\n",
        "\n",
        "    except (sqlite3.Error, Exception) as e:\n",
        "        raise e\n"
      ],
      "metadata": {
        "id": "OVSqv-rANRIZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to query the IRIS API and return parsed XML."
      ],
      "metadata": {
        "id": "2WA_8IP-NfIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_iris_api(url_params: list[dict[str, str]] = None) -> xml.etree.ElementTree.Element:\n",
        "    \"\"\"Call the IRIS API endpoint and return parsed XML.\n",
        "\n",
        "    :param url_params: List of dictionaries containing URL filtering parameters\n",
        "    :return: XML Element\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        api_url = f\"{iris_api_url_base}?format=xml\"\n",
        "        if url_params is not None:\n",
        "            for current_param in url_params:\n",
        "                for key, val in current_param.items():\n",
        "                    api_url += f\"&{key}={val}\"\n",
        "\n",
        "        api_response = requests.get(api_url)\n",
        "\n",
        "        if api_response.status_code != 200:\n",
        "            # Response was not OK (HTTP 200), unexpected result.\n",
        "            raise ConnectionError(f\"HTTP Code {api_response.status_code}, Problem connecting to the IRIS API\")\n",
        "\n",
        "        # Parse the XML response body.\n",
        "        response_body = api_response.content.decode('utf-8')\n",
        "        return xml.etree.ElementTree.fromstring(response_body)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise e\n"
      ],
      "metadata": {
        "id": "bFbeseRcNgEA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the miniSEED files into memory."
      ],
      "metadata": {
        "id": "DO1kwaTxU4s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if mseed_files.__len__() < 1:\n",
        "        print('Error: No miniSEED files to process.')\n",
        "\n",
        "    else:\n",
        "        print(f\"Attempting to import data from {mseed_files.__len__()} miniSEED files.\")\n",
        "\n",
        "        for current_file in mseed_files:\n",
        "            print(f\"Processing '{current_file}'\")\n",
        "\n",
        "            try:\n",
        "                current_stream = obspy.read(pathname_or_url=current_file)\n",
        "                print(f\"Loaded {current_stream.__len__()} traces from the file.\")\n",
        "\n",
        "                mseed_sources_metadata.append({'mseed_file': current_file,\n",
        "                                               'mseed_metadata': current_stream.traces[0].meta.mseed})\n",
        "\n",
        "                for current_trace in current_stream:\n",
        "                    mseed_traces.append(current_trace)\n",
        "\n",
        "            except IOError:\n",
        "                print(f\"Exception: Unable to open file '{current_file}'.\")\n",
        "\n",
        "        print(f\"Imported a total of {mseed_traces.__len__()} traces from all sources.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "dh4jRIoMVxEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5c1c4a-77fa-440c-a546-3034a3cbf9e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to import data from 3 miniSEED files.\n",
            "Processing 'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP01.mseed'\n",
            "Loaded 15 traces from the file.\n",
            "Processing 'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP02.mseed'\n",
            "Loaded 5 traces from the file.\n",
            "Processing 'https://github.com/joestanis/USGS-SAC-25-12553801-DE-RM/raw/refs/heads/main/data/SEP03.mseed'\n",
            "Loaded 12 traces from the file.\n",
            "Imported a total of 32 traces from all sources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provision a database with proper normal form and constraints."
      ],
      "metadata": {
        "id": "63fpELbwIxNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and initialize the code lookup tables."
      ],
      "metadata": {
        "id": "G3wI1LkGj4Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    # Create the database schema for the NETWORK foreign key table.\n",
        "    print(f\"Creating the [{table_names['network_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['network_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                network_code TEXT NOT NULL, -- A one or two character code identifying the owner of the data\n",
        "                CONSTRAINT network_code_unique UNIQUE (network_code));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the NETWORK table.\n",
        "        print(f\"Initializing the [{table_names['network_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['network_codes'])\n",
        "\n",
        "    # Create the database schema for the STATION foreign key table.\n",
        "    print(f\"Creating the [{table_names['station_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['station_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                station_code TEXT NOT NULL, -- A one to five character identifier for the station recording the data\n",
        "                CONSTRAINT station_code_unique UNIQUE (station_code));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the STATION table.\n",
        "        print(f\"Initializing the [{table_names['station_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['station_codes'])\n",
        "\n",
        "    # Create the database schema for the LOCATION foreign key table.\n",
        "    print(f\"Creating the [{table_names['location_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['location_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                location_code TEXT NOT NULL, -- A two character code used to uniquely identify different data streams at a single station\n",
        "                CONSTRAINT location_code_unique UNIQUE (location_code));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the LOCATION table.\n",
        "        print(f\"Initializing the [{table_names['location_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['location_codes'])\n",
        "\n",
        "    # Create the database schema for the CHANNEL foreign key table.\n",
        "    print(f\"Creating the [{table_names['channel_codes']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['channel_codes']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                channel_code TEXT NOT NULL, -- A three character code identifying the band, instrument type, and sensor orientation\n",
        "                CONSTRAINT channel_code_unique UNIQUE (channel_code));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the CHANNEL table.\n",
        "        print(f\"Initializing the [{table_names['channel_codes']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['channel_codes'])\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "Lz7dBheJVsob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08051f22-6714-416b-a816-5002803b485f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the [network_codes] table\n",
            "Initializing the [network_codes] table.\n",
            "Creating the [station_codes] table\n",
            "Initializing the [station_codes] table.\n",
            "Creating the [location_codes] table\n",
            "Initializing the [location_codes] table.\n",
            "Creating the [channel_codes] table\n",
            "Initializing the [channel_codes] table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and initialize the table to contain information about each trace set."
      ],
      "metadata": {
        "id": "ck_zwkUSiSO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    # Create the database schema for the TRACES table.\n",
        "    print(f\"Creating the [{table_names['mseed_traces']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['mseed_traces']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                network_id INTEGER NOT NULL, -- Foreign key to NETWORK.id\n",
        "                station_id INTEGER NOT NULL, -- Foreign key to STATION.id\n",
        "                location_id INTEGER NOT NULL, -- Foreign key to LOCATION.id\n",
        "                channel_id INTEGER NOT NULL, -- Foreign key to CHANNEL.id\n",
        "                starttime REAL, -- Unix timestamp UTC\n",
        "                endtime REAL, -- Unix timestamp UTC\n",
        "                sampling_rate REAL, -- Rate of samples captured, in Hz\n",
        "                delta REAL, -- Time increment between data points\n",
        "                npts INTEGER, -- Number of sampling points in the trace\n",
        "                calib REAL, -- Trace calibration\n",
        "                site_info_id INTEGER NOT NULL, -- Foreign key to SITE_INFO.id\n",
        "                FOREIGN KEY (network_id) REFERENCES {table_names['network_codes']}(id),\n",
        "                FOREIGN KEY (station_id) REFERENCES {table_names['station_codes']}(id),\n",
        "                FOREIGN KEY (location_id) REFERENCES {table_names['location_codes']}(id),\n",
        "                FOREIGN KEY (channel_id) REFERENCES {table_names['channel_codes']}(id)\n",
        "                FOREIGN KEY (site_info_id) REFERENCES {table_names['site_info']}(id));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the TRACES table.\n",
        "        print(f\"Initializing the [{table_names['mseed_traces']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['mseed_traces'])\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "11Vtmd_5iSWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3bd989-b7cc-4df7-987c-86059c5871a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the [mseed_traces] table\n",
            "Initializing the [mseed_traces] table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and initialize the table for holding the miniSEED samples data."
      ],
      "metadata": {
        "id": "xnJzdeGdiZEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    # Create the database schema for the SAMPLES table.\n",
        "    print(f\"Creating the [{table_names['mseed_samples']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['mseed_samples']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                trace_id INTEGER, -- Foreign key to TRACES.id\n",
        "                sequence_num INTEGER, -- Sequence number of the individual sample\n",
        "                sample_value INTEGER, -- Value of the individual sample\n",
        "                FOREIGN KEY (trace_id) REFERENCES {table_names['mseed_traces']}(id));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the SAMPLES table.\n",
        "        print(f\"Initializing the [{table_names['mseed_samples']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['mseed_samples'])\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "VqoeRDSdiZOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f234e504-848f-42df-cf9e-87a06192878a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the [mseed_samples] table\n",
            "Initializing the [mseed_samples] table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and initialize the table for holding information about the trace sites."
      ],
      "metadata": {
        "id": "3C6MNsROidFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "\n",
        "    # Create the database schema for the SITE_INFO table containing metadata about each target site (network + station).\n",
        "    print(f\"Creating the [{table_names['site_info']}] table\")\n",
        "    sql_query = f\"\"\"CREATE TABLE IF NOT EXISTS [{table_names['site_info']}] (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                network_id INTEGER NOT NULL, -- Foreign key to NETWORK.id\n",
        "                station_id INTEGER NOT NULL, -- Foreign key to STATION.id\n",
        "                latitude REAL, -- Decimal degrees of the site East-West location\n",
        "                longitude REAL, -- Decimal degrees of the site North-South location\n",
        "                site_name TEXT, -- Descriptive name for the site\n",
        "                CONSTRAINT site_info_unique UNIQUE (network_id, station_id),\n",
        "                FOREIGN KEY (network_id) REFERENCES {table_names['network_codes']}(id),\n",
        "                FOREIGN KEY (station_id) REFERENCES {table_names['station_codes']}(id));\"\"\"\n",
        "    sql_result = sql_exec(sql=sql_query)\n",
        "    if sql_result is not None:\n",
        "        # Reset the STATION table.\n",
        "        print(f\"Initializing the [{table_names['site_info']}] table.\")\n",
        "        sql_result = sql_truncate_table(table_name=table_names['site_info'])\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "rTx9Od3TidPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e74066-fc6b-4446-b6e2-07ac6cc6ab03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the [site_info] table\n",
            "Initializing the [site_info] table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the miniSEED data into the newly created database."
      ],
      "metadata": {
        "id": "fYDRa2gsJPWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if mseed_traces.__len__() < 1:\n",
        "        print('Error: no miniSEED traces to import.')\n",
        "    else:\n",
        "\n",
        "        counter_traces = 1\n",
        "        for current_trace in mseed_traces:\n",
        "            print(\n",
        "                f\"Importing trace {counter_traces} of {mseed_traces.__len__()} into the [{table_names['mseed_traces']}] table.\")\n",
        "\n",
        "            network_id = fields_to_id(table_name=table_names['network_codes'],\n",
        "                                      search_values={'network_code': current_trace.stats.network},\n",
        "                                      insert_if_missing=True)\n",
        "            if network_id is None:\n",
        "                # Failed to fetch the required ID, skip to the next trace.\n",
        "                continue\n",
        "\n",
        "            station_id = fields_to_id(table_name=table_names['station_codes'],\n",
        "                                      search_values={'station_code': current_trace.stats.station},\n",
        "                                      insert_if_missing=True)\n",
        "            if station_id is None:\n",
        "                # Failed to fetch the required ID, skip to the next trace.\n",
        "                continue\n",
        "\n",
        "            location_id = fields_to_id(table_name=table_names['location_codes'],\n",
        "                                       search_values={'location_code': current_trace.stats.location},\n",
        "                                       insert_if_missing=True)\n",
        "            if location_id is None:\n",
        "                # Failed to fetch the required ID, skip to the next trace.\n",
        "                continue\n",
        "\n",
        "            channel_id = fields_to_id(table_name=table_names['channel_codes'],\n",
        "                                      search_values={'channel_code': current_trace.stats.channel},\n",
        "                                      insert_if_missing=True)\n",
        "            if channel_id is None:\n",
        "                # Failed to fetch the required ID, skip to the next trace.\n",
        "                continue\n",
        "\n",
        "            site_info_id = fields_to_id(table_name=table_names['site_info'],\n",
        "                                        search_values={'network_id': network_id, 'station_id': station_id},\n",
        "                                        insert_if_missing=True)\n",
        "            if site_info_id is None:\n",
        "                # Failed to fetch the required ID, skip to the next trace.\n",
        "                continue\n",
        "\n",
        "            trace_data = {\n",
        "                'network_id': network_id,\n",
        "                'station_id': station_id,\n",
        "                'location_id': location_id,\n",
        "                'channel_id': channel_id,\n",
        "                'starttime': current_trace.stats.starttime.timestamp,\n",
        "                'endtime': current_trace.stats.endtime.timestamp,\n",
        "                'sampling_rate': current_trace.stats.sampling_rate,\n",
        "                'delta': current_trace.stats.delta,\n",
        "                'npts': current_trace.stats.npts,\n",
        "                'calib': current_trace.stats.calib,\n",
        "                'site_info_id': site_info_id\n",
        "            }\n",
        "\n",
        "            trace_id_last_insert = sql_insert(table_name=table_names['mseed_traces'], insert_data=trace_data)\n",
        "            counter_traces += 1\n",
        "\n",
        "            if trace_id_last_insert:\n",
        "                # Positive row ID, implying a successful insert, so proceed with loading the associated trace samples.\n",
        "                print(\n",
        "                    f\"Importing {current_trace.data.__len__()} samples into the [{table_names['mseed_samples']}] table.\")\n",
        "\n",
        "                samples_field_names = [\n",
        "                    'trace_id',\n",
        "                    'sequence_num',\n",
        "                    'sample_value'\n",
        "                ]\n",
        "\n",
        "            # Build the samples data for bulk import.\n",
        "            samples_data = []\n",
        "            samples_list = current_trace.data.tolist()\n",
        "            counter_samples = 0\n",
        "            for current_sample in samples_list:\n",
        "                samples_data.append((trace_id_last_insert, counter_samples, current_sample))\n",
        "                counter_samples += 1\n",
        "\n",
        "            # For improved performance use sql_insert_many to bulk import the sample data points rather than importing one at a time using sql_insert.\n",
        "            sql_insert_many(table_name=table_names['mseed_samples'], field_names=samples_field_names,\n",
        "                            field_values=samples_data)\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "2nfAL5tBVwLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595a50b3-2f3c-4f13-a6a1-a91db64a839a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing trace 1 of 32 into the [mseed_traces] table.\n",
            "Importing 221810 samples into the [mseed_samples] table.\n",
            "Importing trace 2 of 32 into the [mseed_traces] table.\n",
            "Importing 380100 samples into the [mseed_samples] table.\n",
            "Importing trace 3 of 32 into the [mseed_traces] table.\n",
            "Importing 107800 samples into the [mseed_samples] table.\n",
            "Importing trace 4 of 32 into the [mseed_traces] table.\n",
            "Importing 2300 samples into the [mseed_samples] table.\n",
            "Importing trace 5 of 32 into the [mseed_traces] table.\n",
            "Importing 87700 samples into the [mseed_samples] table.\n",
            "Importing trace 6 of 32 into the [mseed_traces] table.\n",
            "Importing 80700 samples into the [mseed_samples] table.\n",
            "Importing trace 7 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 8 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 9 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 10 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 11 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 12 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 13 of 32 into the [mseed_traces] table.\n",
            "Importing 100 samples into the [mseed_samples] table.\n",
            "Importing trace 14 of 32 into the [mseed_traces] table.\n",
            "Importing 3500 samples into the [mseed_samples] table.\n",
            "Importing trace 15 of 32 into the [mseed_traces] table.\n",
            "Importing 7721191 samples into the [mseed_samples] table.\n",
            "Importing trace 16 of 32 into the [mseed_traces] table.\n",
            "Importing 1204890 samples into the [mseed_samples] table.\n",
            "Importing trace 17 of 32 into the [mseed_traces] table.\n",
            "Importing 2900 samples into the [mseed_samples] table.\n",
            "Importing trace 18 of 32 into the [mseed_traces] table.\n",
            "Importing 6372700 samples into the [mseed_samples] table.\n",
            "Importing trace 19 of 32 into the [mseed_traces] table.\n",
            "Importing 2970 samples into the [mseed_samples] table.\n",
            "Importing trace 20 of 32 into the [mseed_traces] table.\n",
            "Importing 1020691 samples into the [mseed_samples] table.\n",
            "Importing trace 21 of 32 into the [mseed_traces] table.\n",
            "Importing 2846160 samples into the [mseed_samples] table.\n",
            "Importing trace 22 of 32 into the [mseed_traces] table.\n",
            "Importing 216200 samples into the [mseed_samples] table.\n",
            "Importing trace 23 of 32 into the [mseed_traces] table.\n",
            "Importing 2628900 samples into the [mseed_samples] table.\n",
            "Importing trace 24 of 32 into the [mseed_traces] table.\n",
            "Importing 113900 samples into the [mseed_samples] table.\n",
            "Importing trace 25 of 32 into the [mseed_traces] table.\n",
            "Importing 130700 samples into the [mseed_samples] table.\n",
            "Importing trace 26 of 32 into the [mseed_traces] table.\n",
            "Importing 105500 samples into the [mseed_samples] table.\n",
            "Importing trace 27 of 32 into the [mseed_traces] table.\n",
            "Importing 177800 samples into the [mseed_samples] table.\n",
            "Importing trace 28 of 32 into the [mseed_traces] table.\n",
            "Importing 195800 samples into the [mseed_samples] table.\n",
            "Importing trace 29 of 32 into the [mseed_traces] table.\n",
            "Importing 993600 samples into the [mseed_samples] table.\n",
            "Importing trace 30 of 32 into the [mseed_traces] table.\n",
            "Importing 358900 samples into the [mseed_samples] table.\n",
            "Importing trace 31 of 32 into the [mseed_traces] table.\n",
            "Importing 570900 samples into the [mseed_samples] table.\n",
            "Importing trace 32 of 32 into the [mseed_traces] table.\n",
            "Importing 250441 samples into the [mseed_samples] table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve location data for each site which provided sample data."
      ],
      "metadata": {
        "id": "y3eCdKjIOQ5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a list containing dictionaries for each site identified during the import."
      ],
      "metadata": {
        "id": "w4Y4eE3qOTZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Initialize the temporary container for the site info.\n",
        "    sites_info: list[dict[str, any]] = []\n",
        "\n",
        "    sites_sql_query = f\"\"\"SELECT * FROM [{table_names['site_info']}]\n",
        "                        INNER JOIN [{table_names['network_codes']}] on [{table_names['network_codes']}].id = [{table_names['site_info']}].network_id\n",
        "                        INNER JOIN [{table_names['station_codes']}] on [{table_names['station_codes']}].id = [{table_names['site_info']}].station_id;\"\"\"\n",
        "\n",
        "    sites_sql_result = sql_exec(sql=sites_sql_query)\n",
        "    if sites_sql_result is not None:\n",
        "        for current_site_info in sites_sql_result:\n",
        "            sites_info.append({\n",
        "                'network_code': current_site_info['network_code'],\n",
        "                'station_code': current_site_info['station_code'],\n",
        "                'latitude': current_site_info['latitude'],\n",
        "                'longitude': current_site_info['longitude'],\n",
        "                'site_name': current_site_info['site_name'],\n",
        "            })\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "MM7wK5vIORoZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For each site query the IRIS API to retrieve the latitude, longitude, and site name."
      ],
      "metadata": {
        "id": "GEGe7twwOb5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if sites_info is not None:\n",
        "\n",
        "        # Extract the list of network codes and station codes to separate lists.\n",
        "        network_codes_list = [temp['network_code'] for temp in sites_info]\n",
        "        station_codes_list = [temp['station_code'] for temp in sites_info]\n",
        "\n",
        "        # Call the IRIS API.\n",
        "        print('Fetching data from the IRIS API.')\n",
        "        url_params = [{\n",
        "            'network': ','.join(network_codes_list),\n",
        "            'station': ','.join(station_codes_list)\n",
        "        }]\n",
        "        xml_data = fetch_iris_api(url_params=url_params)\n",
        "\n",
        "        # IRIS results are namespaced so extract the current namespace from the root tag.\n",
        "        xmlns = re.compile('{(.*)}').findall(xml_data.tag)[0]\n",
        "        iris_ns = {'iris': xmlns}\n",
        "\n",
        "        # Locate each site in the results and add missing information to the dictionary.\n",
        "        for current_site in sites_info:\n",
        "            xpath = f\".//iris:Network[@code='{current_site['network_code']}']/iris:Station[@code='{current_site['station_code']}']\"\n",
        "            found_site = xml_data.find(path=xpath, namespaces=iris_ns)\n",
        "            current_site['latitude'] = found_site.find(path='./iris:Latitude', namespaces=iris_ns).text\n",
        "            current_site['longitude'] = found_site.find(path='./iris:Longitude', namespaces=iris_ns).text\n",
        "            current_site['site_name'] = found_site.find(path='./iris:Site/iris:Name', namespaces=iris_ns).text\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOPTTle1OeBX",
        "outputId": "c3b3a86d-df24-4d7e-bf6d-d0dc616f1ecd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from the IRIS API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query the IRIS API for additional HOA and SUG stations of interest."
      ],
      "metadata": {
        "id": "KMNUSqSuOhfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if sites_info is not None:\n",
        "        # Specify API parameters to retrieve all HOA and SUG stations.\n",
        "        url_params = [{\n",
        "            'station': 'HOA,SUG'\n",
        "        }]\n",
        "\n",
        "        # Call the IRIS API.\n",
        "        print('Fetching data from the IRIS API.')\n",
        "        xml_data = fetch_iris_api(url_params=url_params)\n",
        "\n",
        "        # IRIS results are namespaced so extract the current namespace from the root tag.\n",
        "        xmlns = re.compile('{(.*)}').findall(xml_data.tag)[0]\n",
        "        iris_ns = {'iris': xmlns}\n",
        "\n",
        "        # Locate the new sites and add them to the dictionary.\n",
        "        found_networks = xml_data.findall(path='.//iris:Network', namespaces=iris_ns)\n",
        "        for current_network in found_networks:\n",
        "            new_network = current_network.get('code')\n",
        "\n",
        "            found_stations = current_network.findall(path='./iris:Station', namespaces=iris_ns)\n",
        "            for current_station in found_stations:\n",
        "                new_station = current_station.get('code')\n",
        "                new_latitude = current_station.find(path='./iris:Latitude', namespaces=iris_ns).text\n",
        "                new_longitude = current_station.find(path='./iris:Longitude', namespaces=iris_ns).text\n",
        "                new_name = current_station.find(path='./iris:Site/iris:Name', namespaces=iris_ns).text\n",
        "\n",
        "                # Located all required information for the new site, add it to the dictionary.\n",
        "                sites_info.append({\n",
        "                    'network_code': new_network,\n",
        "                    'station_code': new_station,\n",
        "                    'latitude': new_latitude,\n",
        "                    'longitude': new_longitude,\n",
        "                    'site_name': new_name\n",
        "                })\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vAaZbyjOh6o",
        "outputId": "940f06cb-3e8c-409a-d536-fa107fa358e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from the IRIS API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add any new network and station codes to the database and update site information."
      ],
      "metadata": {
        "id": "JuEZnoZNOn50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    if sites_info is not None:\n",
        "\n",
        "        try:\n",
        "            # Iterate the sites dictionary to add new codes and update site information.\n",
        "            print('Adding new codes to the database and updating site information.')\n",
        "\n",
        "            for current_site in sites_info:\n",
        "\n",
        "                network_id = fields_to_id(table_name=table_names['network_codes'],\n",
        "                                          search_values={'network_code': current_site['network_code']},\n",
        "                                          insert_if_missing=True)\n",
        "                if network_id is None:\n",
        "                    # Failed to fetch the required ID, skip to the next site.\n",
        "                    continue\n",
        "\n",
        "                station_id = fields_to_id(table_name=table_names['station_codes'],\n",
        "                                          search_values={'station_code': current_site['station_code']},\n",
        "                                          insert_if_missing=True)\n",
        "                if station_id is None:\n",
        "                    # Failed to fetch the required ID, skip to the next site.\n",
        "                    continue\n",
        "\n",
        "                site_id = fields_to_id(table_name=table_names['site_info'],\n",
        "                                          search_values={'network_id': network_id, 'station_id': station_id},\n",
        "                                          insert_if_missing=True)\n",
        "                if site_id is None:\n",
        "                    # Failed to fetch the required ID, skip to the next site.\n",
        "                    continue\n",
        "\n",
        "                # Update the site info\n",
        "                sql_query = f\"\"\"UPDATE [{table_names['site_info']}] SET [latitude] = {current_site['latitude']},\n",
        "                                [longitude] = {current_site['longitude']},\n",
        "                                [site_name] = '{current_site['site_name']}'\n",
        "                                WHERE [id] = {site_id};\"\"\"\n",
        "\n",
        "                with sqlite3.connect(database=mseed_db_filename) as db_conn:\n",
        "                    db_cursor = db_conn.cursor()\n",
        "                    db_cursor.execute(sql_query)\n",
        "                    db_conn.commit()\n",
        "\n",
        "        except sqlite3.Error as e:\n",
        "            print(f\"Exception: SQLite {' '.join(e.args)}.\")\n",
        "\n",
        "        finally:\n",
        "            db_conn.close()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Exception: {e}\")\n"
      ],
      "metadata": {
        "id": "V6Z7w99xOrQ0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a visualization for the data."
      ],
      "metadata": {
        "id": "f6IG4LfwZ0-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('TODO')"
      ],
      "metadata": {
        "id": "vOiB7Rk1Z4Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90042f05-8c97-4a72-8a49-1707d169f91c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TODO\n"
          ]
        }
      ]
    }
  ]
}